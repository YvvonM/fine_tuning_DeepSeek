{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:59:41.776281Z","iopub.execute_input":"2025-02-05T09:59:41.776573Z","iopub.status.idle":"2025-02-05T09:59:42.070706Z","shell.execute_reply.started":"2025-02-05T09:59:41.776551Z","shell.execute_reply":"2025-02-05T09:59:42.070083Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### Installing Packages ","metadata":{}},{"cell_type":"code","source":"#Installing libraries\n#%%capture\n!pip install unsloth\n!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T09:59:42.071733Z","iopub.execute_input":"2025-02-05T09:59:42.072147Z","iopub.status.idle":"2025-02-05T10:00:18.648578Z","shell.execute_reply.started":"2025-02-05T09:59:42.072116Z","shell.execute_reply":"2025-02-05T10:00:18.647758Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.1.8-py3-none-any.whl.metadata (53 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.1.4 (from unsloth)\n  Downloading unsloth_zoo-2025.1.5-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.29.post2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.13-py3-none-any.whl.metadata (9.4 kB)\nCollecting transformers!=4.47.0,>=4.46.1 (from unsloth)\n  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.1)\nCollecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n  Downloading trl-0.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.27.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (13.9.4)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.1.4->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.1.4->unsloth) (11.0.0)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.12.14)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\nDownloading unsloth-2025.1.8-py3-none-any.whl (175 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m175.5/175.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading trl-0.14.0-py3-none-any.whl (313 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.1.5-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading xformers-0.0.29.post1-cp310-cp310-manylinux_2_28_x86_64.whl (15.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.13-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, shtab, tyro, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, bitsandbytes, unsloth\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\nSuccessfully installed bitsandbytes-0.45.1 cut_cross_entropy-25.1.1 shtab-1.7.1 transformers-4.48.2 triton-3.1.0 trl-0.14.0 tyro-0.9.13 unsloth-2025.1.8 unsloth_zoo-2025.1.5 xformers-0.0.29.post1\nCollecting git+https://github.com/unslothai/unsloth.git\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-req-build-9epnvw64\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-req-build-9epnvw64\n  Resolved https://github.com/unslothai/unsloth.git to commit 038e6d4c8d40207a87297ab3aaf787c19b1006d1\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unsloth: filename=unsloth-2025.1.8-py3-none-any.whl size=174982 sha256=5f4246ac0ed48cda4dacfe497eb43f0ee01dcf9105029fd568c3114ae8561e2e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-dijw31xt/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth\n  Attempting uninstall: unsloth\n    Found existing installation: unsloth 2025.1.8\n    Uninstalling unsloth-2025.1.8:\n      Successfully uninstalled unsloth-2025.1.8\nSuccessfully installed unsloth-2025.1.8\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Importing libraries","metadata":{}},{"cell_type":"code","source":"#modules for fine-tuning\nfrom unsloth import FastLanguageModel\nimport torch\nfrom trl import SFTTrainer\nfrom unsloth import is_bfloat16_supported\n\n#Hugging Face libraries\nfrom huggingface_hub import login\nfrom transformers import TrainingArguments\nfrom datasets import load_dataset\n\n#importing weights and biases\nimport wandb\n\n#importing kaggle secrets\nfrom kaggle_secrets import UserSecretsClient\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:00:18.650377Z","iopub.execute_input":"2025-02-05T10:00:18.650611Z","iopub.status.idle":"2025-02-05T10:00:45.563445Z","shell.execute_reply.started":"2025-02-05T10:00:18.650580Z","shell.execute_reply":"2025-02-05T10:00:45.562696Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Logging in to Hugging Face and weights and biases","metadata":{}},{"cell_type":"code","source":"#Ininitalizing Hugging Face and WnB tokens\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_Token\")\nwnb_token = user_secrets.get_secret(\"wnb\")\n\n#loggin in to hugginface and wandb\nlogin(hf_token)\nwandb.login(key = wnb_token)\nwandb.init(\n    project = 'Fine-tune-Deepseek-R1-Distill-Llama-8B',\n    job_type = 'training',\n    anonymous = 'allow'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:00:45.564531Z","iopub.execute_input":"2025-02-05T10:00:45.564771Z","iopub.status.idle":"2025-02-05T10:00:58.281661Z","shell.execute_reply.started":"2025-02-05T10:00:45.564750Z","shell.execute_reply":"2025-02-05T10:00:58.281000Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myvvonjemmymajala\u001b[0m (\u001b[33myvvonjemmymajala-i-kuku\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250205_100052-ji7hu201</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B/runs/ji7hu201' target=\"_blank\">icy-sunset-4</a></strong> to <a href='https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B' target=\"_blank\">https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B/runs/ji7hu201' target=\"_blank\">https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B/runs/ji7hu201</a>"},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B/runs/ji7hu201?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ee21e1b3250>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### Loading The Model And Tokenizer","metadata":{}},{"cell_type":"code","source":"#setting parameters\nmax_seq_length = 2048\ndtype = None\nload_in_4bit = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:00:58.282402Z","iopub.execute_input":"2025-02-05T10:00:58.282607Z","iopub.status.idle":"2025-02-05T10:00:58.286950Z","shell.execute_reply.started":"2025-02-05T10:00:58.282588Z","shell.execute_reply":"2025-02-05T10:00:58.286144Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = hf_token\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:00:58.287820Z","iopub.execute_input":"2025-02-05T10:00:58.288135Z","iopub.status.idle":"2025-02-05T10:01:46.335259Z","shell.execute_reply.started":"2025-02-05T10:00:58.288091Z","shell.execute_reply":"2025-02-05T10:01:46.334591Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.1.8: Fast Llama patching. Transformers: 4.48.2.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acd7ebeade784330865813d0f5c2f50f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5a4ece1d633499a9b19bab61fe1b0f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cf43f732aba442984d137c0c207ba1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d20438529f4452992197dfdaa305558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a066a97e9fbf47d2a9faee86407ff2b9"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Testing DeepSeek Before Fine-Tuning","metadata":{}},{"cell_type":"code","source":"#setting the prompt style\nprompt_style = \"\"\"\nBelow is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>{}\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:01:46.335964Z","iopub.execute_input":"2025-02-05T10:01:46.336181Z","iopub.status.idle":"2025-02-05T10:01:46.340723Z","shell.execute_reply.started":"2025-02-05T10:01:46.336163Z","shell.execute_reply":"2025-02-05T10:01:46.340121Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#creating a test medical question\nquestion = \"A 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\"\n\n#enable optimized inference model for unsloth models\nFastLanguageModel.for_inference(model)\n\n#format the question using the structured promot & tokenize it\ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\n#generate a response using the model\noutput = model.generate(input_ids = inputs.input_ids,\n                       attention_mask = inputs.attention_mask,\n                       max_new_tokens = 1200,\n                       use_cache = True)\n\n#Decoding the generated output tokens into human readable text\nresponse= tokenizer.batch_decode(output)\nprint(response[0].split(\"### Response\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:01:46.342904Z","iopub.execute_input":"2025-02-05T10:01:46.343139Z","iopub.status.idle":"2025-02-05T10:02:45.565541Z","shell.execute_reply.started":"2025-02-05T10:01:46.343120Z","shell.execute_reply":"2025-02-05T10:02:45.564605Z"}},"outputs":[{"name":"stdout","text":":\n<think>\nOkay, so I'm trying to figure out what cystometry would show for this 61-year-old woman. She's been dealing with involuntary urine loss when she coughs or sneezes but doesn't leak at night. She's had a gynecological exam and a Q-tip test. I need to determine what the cystometry results would likely reveal about her residual volume and detrusor contractions.\n\nFirst, let me break down the information. Involuntary urine loss during activities like coughing suggests a possible issue with the lower urinary tract, maybe the bladder. The fact that she doesn't leak at night points away from something like nocturia, which is more common in conditions like overactive bladder or perhaps neurogenic bladder. So, it's more likely a daytime issue, perhaps stress urinary incontinence.\n\nShe underwent a gynecological exam and a Q-tip test. I'm not entirely sure about the specifics of the Q-tip test, but from what I recall, it's a diagnostic tool used to assess urethral function. It involves inserting a Q-tip catheter into the urethra to measure pressure and determine if the urethral sphincter is functioning properly. If the sphincter doesn't close properly, it can lead to incontinence.\n\nNow, thinking about cystometry. Cystometry is a diagnostic procedure where a catheter is inserted into the bladder to fill it with a liquid and measure the pressure as the bladder fills and empties. It's used to assess things like bladder capacity, compliance, and the presence of detrusor contractions. Detrusor contractions are involuntary muscle spasms of the detrusor muscle, which is the smooth muscle layer of the bladder. These contractions can cause increased pressure in the bladder, leading to incontinence.\n\nGiven that she has a history of involuntary urine loss during activities that increase abdominal pressure (like coughing), it's plausible that her detrusor contractions are heightened, causing the bladder to have a lower capacity before it can be adequately filled, leading to urgency and leakage.\n\nSo, if she has an overactive bladder with increased detrusor contractions, the cystometry would likely show reduced bladder capacity because the contractions are more frequent or stronger, making the bladder empty more quickly. Additionally, the residual volume might be normal, but the detrusor contractions would be abnormal, meaning they occur involuntarily at inappropriate times.\n\nI'm also thinking about other possible causes. Could there be a nerve injury affecting bladder control? That could lead to similar symptoms. In that case, the cystometry might show neurogenic detrusor contractions, which are different from the usual overactive ones. But since she doesn't leak at night, it's less likely to be neurogenic, as night-time leakage is common in such cases.\n\nAnother possibility is that the issue is with the urethral sphincter, making it less able to retain urine. The Q-tip test might have shown abnormal findings indicating sphincter dysfunction. In that case, the cystometry might show normal bladder capacity but impaired sphincter function, leading to incontinence.\n\nBut given that she's 61 and the issue is more about activities that increase intra-abdominal pressure, it's more likely a bladder issue. So, focusing on detrusor contractions, the cystometry would show increased activity, leading to reduced bladder volume and possible urge to void.\n\nIn summary, the cystometry would likely reveal that her residual volume is low due to frequent or strong detrusor contractions, and these contractions are occurring involuntarily, contributing to her symptoms.\n</think>\n\nBased on the provided information and analysis, the cystometry for the 61-year-old woman would most likely reveal the following:\n\n1. **Residual Volume**: The test would show a reduced residual volume in the bladder. This is because the detrusor contractions are occurring more frequently or with increased strength, leading to the bladder emptying sooner than normal.\n\n2. **Detrusor Contractions**: The cystometry would indicate abnormal detrusor contractions. These contractions are involuntary and occur at inappropriate times, contributing to the involuntary urine loss during activities like coughing.\n\nIn conclusion, the cystometry results would highlight a low residual volume due to increased detrusor contractions, which are occurring involuntarily, thereby causing the symptoms described.<ï½œendâ–ofâ–sentenceï½œ>\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### Fine-Tuning Step By Step","metadata":{}},{"cell_type":"code","source":"#updating the training prompt_style. Changing the position of the </think> tag\ntrain_prompt_style = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \nWrite a response that appropriately completes the request. \nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\n\n### Instruction:\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \nPlease answer the following medical question. \n\n### Question:\n{}\n\n### Response:\n<think>\n{}\n</think>\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:45.566586Z","iopub.execute_input":"2025-02-05T10:02:45.566879Z","iopub.status.idle":"2025-02-05T10:02:45.571767Z","shell.execute_reply.started":"2025-02-05T10:02:45.566855Z","shell.execute_reply":"2025-02-05T10:02:45.570954Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#dowloading the dataset\ndataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\",\n                       \"en\", \n                       split = \"train[0:650]\",\n                       trust_remote_code = True)\n\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:45.572616Z","iopub.execute_input":"2025-02-05T10:02:45.572846Z","iopub.status.idle":"2025-02-05T10:02:50.694285Z","shell.execute_reply.started":"2025-02-05T10:02:45.572826Z","shell.execute_reply":"2025-02-05T10:02:50.693527Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d816d30476b048f49f69f5325d52803d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"medical_o1_sft.json:   0%|          | 0.00/74.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ea48faf87b349f1b2dc29fdef89395e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/25371 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f7dd3edf65a4b1da0417e818149ed3c"}},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Question', 'Complex_CoT', 'Response'],\n    num_rows: 650\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"#formating the dataset to fit the prompt-style\nEOS_TOKEN = tokenizer.eos_token\nEOS_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:50.695183Z","iopub.execute_input":"2025-02-05T10:02:50.695468Z","iopub.status.idle":"2025-02-05T10:02:50.701196Z","shell.execute_reply.started":"2025-02-05T10:02:50.695425Z","shell.execute_reply":"2025-02-05T10:02:50.700338Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'<ï½œendâ–ofâ–sentenceï½œ>'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"#Formatting the prompt function\ndef formatting_prompts_func(examples):\n    inputs = examples[\"Question\"]\n    cots = examples[\"Complex_CoT\"]\n    outputs = examples[\"Response\"]\n    texts = []\n    for input, cot, output in zip(inputs, cots, outputs):\n        text = train_prompt_style.format(input, cot, output) + EOS_TOKEN\n        texts.append(text)\n    return {\n        \"text\": texts,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:50.702367Z","iopub.execute_input":"2025-02-05T10:02:50.702678Z","iopub.status.idle":"2025-02-05T10:02:50.712955Z","shell.execute_reply.started":"2025-02-05T10:02:50.702649Z","shell.execute_reply":"2025-02-05T10:02:50.712292Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#update dataset formatting\n#dataset_finetune = dataset.map(formatting_prompts_func, batched = True)\ndataset = dataset.map(formatting_prompts_func, batched = True,)\ndataset[\"text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:50.713686Z","iopub.execute_input":"2025-02-05T10:02:50.713923Z","iopub.status.idle":"2025-02-05T10:02:50.767575Z","shell.execute_reply.started":"2025-02-05T10:02:50.713905Z","shell.execute_reply":"2025-02-05T10:02:50.766916Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/650 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd293766bf5b4cda9ab1335a738c0164"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\"Below is an instruction that describes a task, paired with an input that provides further context. \\nWrite a response that appropriately completes the request. \\nBefore answering, think carefully about the question and create a step-by-step chain of thoughts to ensure a logical and accurate response.\\n\\n### Instruction:\\nYou are a medical expert with advanced knowledge in clinical reasoning, diagnostics, and treatment planning. \\nPlease answer the following medical question. \\n\\n### Question:\\nA 61-year-old woman with a long history of involuntary urine loss during activities like coughing or sneezing but no leakage at night undergoes a gynecological exam and Q-tip test. Based on these findings, what would cystometry most likely reveal about her residual volume and detrusor contractions?\\n\\n### Response:\\n<think>\\nOkay, let's think about this step by step. There's a 61-year-old woman here who's been dealing with involuntary urine leakages whenever she's doing something that ups her abdominal pressure like coughing or sneezing. This sounds a lot like stress urinary incontinence to me. Now, it's interesting that she doesn't have any issues at night; she isn't experiencing leakage while sleeping. This likely means her bladder's ability to hold urine is fine when she isn't under physical stress. Hmm, that's a clue that we're dealing with something related to pressure rather than a bladder muscle problem. \\n\\nThe fact that she underwent a Q-tip test is intriguing too. This test is usually done to assess urethral mobility. In stress incontinence, a Q-tip might move significantly, showing urethral hypermobility. This kind of movement often means there's a weakness in the support structures that should help keep the urethra closed during increases in abdominal pressure. So, that's aligning well with stress incontinence.\\n\\nNow, let's think about what would happen during cystometry. Since stress incontinence isn't usually about sudden bladder contractions, I wouldn't expect to see involuntary detrusor contractions during this test. Her bladder isn't spasming or anything; it's more about the support structure failing under stress. Plus, she likely empties her bladder completely because stress incontinence doesn't typically involve incomplete emptying. So, her residual volume should be pretty normal. \\n\\nAll in all, it seems like if they do a cystometry on her, it will likely show a normal residual volume and no involuntary contractions. Yup, I think that makes sense given her symptoms and the typical presentations of stress urinary incontinence.\\n</think>\\nCystometry in this case of stress urinary incontinence would most likely reveal a normal post-void residual volume, as stress incontinence typically does not involve issues with bladder emptying. Additionally, since stress urinary incontinence is primarily related to physical exertion and not an overactive bladder, you would not expect to see any involuntary detrusor contractions during the test.<ï½œendâ–ofâ–sentenceï½œ>\""},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### Setting up the model using LoRA","metadata":{}},{"cell_type":"code","source":"#Initializing the lora model\nmodel_lora = FastLanguageModel.get_peft_model(\n    model, \n    r = 16,\n    target_modules= [\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\"\n    ],\n    lora_alpha = 16,\n    lora_dropout = 0,\n    bias= 'none',\n    use_gradient_checkpointing = \"unsloth\",\n    random_state = 3402,\n    use_rslora = False,\n    loftq_config = None\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:50.768283Z","iopub.execute_input":"2025-02-05T10:02:50.768521Z","iopub.status.idle":"2025-02-05T10:02:56.699682Z","shell.execute_reply.started":"2025-02-05T10:02:50.768488Z","shell.execute_reply":"2025-02-05T10:02:56.698880Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.1.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#initializing the finetuning trainer\ntrainer = SFTTrainer(\n    model=model_lora,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    #definiing the training arguments\n    args=TrainingArguments(\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        # Use num_train_epochs = 1, warmup_ratio for full training runs!\n        warmup_steps=5,\n        max_steps=60,\n        learning_rate=2e-4,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=10,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:56.700448Z","iopub.execute_input":"2025-02-05T10:02:56.700675Z","iopub.status.idle":"2025-02-05T10:02:59.266729Z","shell.execute_reply.started":"2025-02-05T10:02:56.700656Z","shell.execute_reply":"2025-02-05T10:02:59.265986Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/650 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ce16f25b9ce4b40895c60d7b8fc19fc"}},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"### Training the model","metadata":{}},{"cell_type":"code","source":"#training the model\ntrainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:02:59.267770Z","iopub.execute_input":"2025-02-05T10:02:59.268085Z","iopub.status.idle":"2025-02-05T10:22:42.799074Z","shell.execute_reply.started":"2025-02-05T10:02:59.268059Z","shell.execute_reply":"2025-02-05T10:22:42.798197Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 650 | Num Epochs = 1\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 8 | Total steps = 60\n \"-____-\"     Number of trainable parameters = 41,943,040\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 19:11, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.846300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.459100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.416500</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.393900</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.320000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.328600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Save the fine-tuned model\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T10:22:42.800072Z","iopub.execute_input":"2025-02-05T10:22:42.800393Z","iopub.status.idle":"2025-02-05T10:22:44.329690Z","shell.execute_reply.started":"2025-02-05T10:22:42.800362Z","shell.execute_reply":"2025-02-05T10:22:44.328901Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>â–â–‚â–„â–…â–‡â–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–‚â–„â–…â–‡â–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–…â–ƒâ–â–‚â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–‡â–…â–„â–‚â–</td></tr><tr><td>train/loss</td><td>â–ˆâ–ƒâ–‚â–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1.7911162265714688e+16</td></tr><tr><td>train/epoch</td><td>0.73846</td></tr><tr><td>train/global_step</td><td>60</td></tr><tr><td>train/grad_norm</td><td>0.23088</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.3286</td></tr><tr><td>train_loss</td><td>1.46075</td></tr><tr><td>train_runtime</td><td>1179.8737</td></tr><tr><td>train_samples_per_second</td><td>0.407</td></tr><tr><td>train_steps_per_second</td><td>0.051</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">icy-sunset-4</strong> at: <a href='https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B/runs/ji7hu201' target=\"_blank\">https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B/runs/ji7hu201</a><br> View project at: <a href='https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B' target=\"_blank\">https://wandb.ai/yvvonjemmymajala-i-kuku/Fine-tune-Deepseek-R1-Distill-Llama-8B</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250205_100052-ji7hu201/logs</code>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}